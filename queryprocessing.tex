\section{Query Processing}
\label{sec:query-processing}

In Section~\ref{sec:queries} we described the query language that allows data analysts to interact with model tables. In this Section we describe how these queries are processed by Plato's query processor.
\reminder{To YP: We need to say something about querying the data as infinite models, as the ideas presenting in this section (e.g., pushing computations to the storage representation) cannot be easily generalized to this case.}
%To ease exposition, we will be using a query that accesses the models through functions. However, the same concepts apply also to queries that access models by considering them as infinite tables as explained in Section~\ref{sec:queries}.  

\vspace*{0.5cm}
\begin{example}
\label{xmpl:correlation}
Consider a variation of the running example in which the temperature models are created using an FFT (Fast Fourier Transform) learning algorithm and stored as sets of frequency-amplitude pairs. Given these models, consider the following query asking for pairs of highly correlated temperature sensors. \reminder{To YP: Note that we had to change the learning algorithm used from ARMA to FFT to enable query processing on the storage representation directly} 
\begin{tabbing}
\texttt{SELECT sm1.Sensor, sm2.Sensor}\\
\texttt{FROM sensor\_models AS sm1, sensor\_models AS sm2}\\
\texttt{WHERE corelation(sm1.Model, sm2.Model) > 0.9}
\end{tabbing}
\vspace*{0.5cm}

\reminder{to Yoav (Priority 2): An obvious and inefficient way to find the required pairs is to try all pairs. However, there is a better way, based on the transitivity of correlation. Eg, if corelation(x,y) is very close to 1 and corelation(y,z) is very close to 1 it should be that correlation(x,z) is somewhat close to 1. Let's discuss it because there may be good space for rewriting optimizations, i.e., showing how an optimizer can capture such patterns and execute in more efficient plans.
} \reminder{To YP: I am not sure whether correlation is indeed transitive.}
\end{example}

\paragraph{Processing queries by materializing model values on a grid}
MauveDB \reminder{Add reference} suggested that the analyst specifies a spatiotemporal grid and each model participating in a query returns the quantities at the grid's points. Consequently, the statistical functions of the query can be computed in a straightforward way. \reminder{One MauveDB paper did not follow this approach. We should make sure that we make this distinction when we discuss related work.}

\vspace*{0.5cm}
\begin{example}
The following Plato query utilizes MauveDB's technique. It dictates a grid-based execution of the query of Example~\ref{xmpl:correlation}.
\begin{tabbing}
\texttt{SELECT sm1.Sensor, sm2.Sensor}\\
\texttt{FROM sensor\_models AS sm1, sensor\_models AS sm2}\\
\texttt{LET grid\_start = min\_coord(sm1.Model, sm2.Model)}\\
\texttt{LET grid\_end = max\_coord(sm1.Model, sm2.Model)}\\
\texttt{WHERE corelation(}\=\texttt{grid(sm1.Model, grid\_start, grid\_end, 60)}\\ \>\texttt{grid(sm2.Model, grid\_start, grid\_end, 60)) > 0.9}
\end{tabbing}
\noindent The function $\texttt{grid}(f, l, u, s)$ creates a discrete model $f_d$ that is defined only on the grid defined by the start $l$, the end $u$ and the step $s$.  For every point $t_i = l + is, t_i \leq u$ it is $f_d(t_i) = f(t_i)$.
\end{example}
\vspace*{0.5cm}

While the grid materialization provides a baseline solution, it has two shortcomings. First, the analyst must guess an appropriate grid granularity. A too fine grid will produce accurate results but it will also lead to unnecessarily large discrete models and slow query processing. On the other extreme, a too coarse grid will produce inaccurate results. A better approach is to allow Plato to automatically devise the appropriate grid granularity, based on smoothness of the involved functions.
\reminder{To YF: Is selection of the appropriate grid granularity a solved problem in signal processing? It sounds very close to the sampling problem: How many samples are enough?
}
Still, even with automatic inference of the appropriate grid, the grid-based query processing misses the large opportunity discussed next.\\

%\reminder{Matt, let's back this up with numbers from the energy.}

\paragraph{Processing queries directly on model representations}
%\label{sec:qp-direct-on-models}
Instead of computing the values of a function on a grid and subsequently applying a function, many statistical functions can be performed directly on the storage representation of a model, therefore reaping the benefits of the compression. In the running Example~\ref{xmpl:correlation}, the correlation function query can be executed faster directly on the frequency representation.%
\reminder{to Yannis P: Complete formula that computes correlation from frequencies.}

To enable query processing on the storage representation, the domain specialist designing a learning algorithm can provide Plato with the corresponding implementations of the statistical functions. Consequently, query processing will be automatically using the appropriate implementation (e.g., correlation on the frequency domain). The grid technique will be the last resort, in the case where the domain specialist has not provided an implementation that works directly on the compressed model representation.

\reminder{to Yoav (Priority 1): What do we do if we want to correlate two models that are based on different representations? Eg, consider that $x$ is stored in a frequency representation and $y$ is stored in an ARMA. What is the fastest algorithm for computing the correlation of $x$ and $y$? There should be correlation algorithms that are better than decompressing $x$ and $y$ in the time domain. Are there such algorithms? If no, we should add in proposal. If yes, is it known how many options are available and what is the best option? If no, we should add in the proposal.
}
\reminder{Yoav: I believe you correlate {\em signals}, not models. You can
check whether two models are {\em consistent} with each other, or you
can compute the {\em likelihood} that a model assigns to an observed
signal. As for correlating signals, your example is correct. I don't know of
methods for efficiently computing the correlation between two signals 
that are represented in a way other than the FFT.}

\subsection{Anytime query processing}
\label{sec:anytime}
The domain specialists may elect to structure the storage representation of their models such that it enables the answer of queries with a strict deadline (also known as anytime queries). To enable anytime query processing a model's storage representation should store its components ordered by importance, so that the query result can be still computed (albeit with lower accuracy) by ignoring some of the components.

For example, consider a model produced by the FFT learning algorithm. One possible storage representation of this model is a sequence of frequency-amplitude pairs, sorted by the amplitude of each frequency. Given this storage representation, the query of Example~\ref{xmpl:correlation} can be executed by applying the frequency-based correlation algorithm first at high amplitude frequencies and progressively as time allows to lower amplitude frequencies. Generally, a model representation can be stored in sequences of data where prefixes of increasing size correspond to models of increasing accuracy. Plato will utilize the above representation property to allow both anytime queries that have to be executed within a certain timeframe, as well as queries that return a continuous result with ever increasing accuracy (similar to the interface adopted by works on online aggregation). \reminder{Add reference to online aggregation works}

%\reminder{to Yannis P: spell out syntax of anytime queries. Look if BlinkDb has the concept also. }

%\reminder{Question to Yoav (Priority 1): For the typical model classes (ARMA, Fourier, SVD etc) is there a single and obvious ordering (eg, amplitude in Fourier) that accomodates all typical statistical functions? Or we need to state a problem: Discover the appropriate orders for various functions.}
%\reminder{Yoav: I am not sure what you mean by ``ordering'' either ingeneral or in the context of the Fourier transform. Do you mean something like the ordering of eigen-vectors in SVD by decreasing eigen-values?}
